package com.ragnar.server.search;


import com.ragnar.server.data.metaLog;
import com.ragnar.server.data.responseJson;
import com.ragnar.server.util.DateTimeHepler;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.MultiReader;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.store.IOContext;
import org.apache.lucene.store.RAMDirectory;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.context.annotation.Scope;
import org.springframework.scheduling.annotation.EnableScheduling;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

import java.nio.file.*;
import java.nio.file.Paths;
import java.util.ArrayList;
import java.util.Date;
import java.util.concurrent.ConcurrentLinkedQueue;
import java.util.concurrent.ConcurrentSkipListMap;

@Component
@Scope("singleton")
public class IndexService {

    private Logger log;

    //index cache list
    //private ConcurrentSkipListMap<Long, IndexSharder> CacheIndexList;

    //index main merge
    //todo:main

    //init
    private Analyzer analyzer;
    private IndexWriterConfig ramConfig;
    private IndexWriterConfig diskConfig;

    //Directory
    private RAMDirectory ramDirectory;
    private FSDirectory diskDirectory;

    //reader
    private DirectoryReader diskReader;
    private DirectoryReader ramReader;

    //writer
    private IndexWriter ramWriter;
    private IndexWriter diskWriter;

    //search reader
    //private MultiReader indexReaderObj;

    //searcher
    private IndexSearcher searcher;

    //init the data queue
    private ConcurrentLinkedQueue<metaLog> IndexInputQueue;
    private boolean StopQueue = false;

    //init
    public IndexService() {
        log = LoggerFactory.getLogger(IndexService.class);

        IndexInputQueue = new ConcurrentLinkedQueue<metaLog>();

        //Cache Index List
        //CacheIndexList = new ConcurrentSkipListMap<Long, IndexSharder>();

        //init memory index
        analyzer = new StandardAnalyzer();
        //ramConfig = new IndexWriterConfig(analyzer);
        //ramConfig.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND);
        //ramConfig.setRAMBufferSizeMB(256.0);

        diskConfig = new IndexWriterConfig(analyzer);
        diskConfig.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND);
        diskConfig.setRAMBufferSizeMB(256.0);

        try {
            //init director
            //ramDirectory = new RAMDirectory(FSDirectory
            //        .open(Paths.get("cacheindex")), new IOContext());
            diskDirectory = FSDirectory.open(Paths.get("index"));

            //init writer
            //ramWriter = new IndexWriter(ramDirectory, ramConfig);
            diskWriter = new IndexWriter(diskDirectory, diskConfig);

            //ramWriter.commit();
            diskWriter.commit();

            //init reader
            diskReader = DirectoryReader.open(diskDirectory);
            //ramReader = DirectoryReader.open(ramDirectory);

            //indexReaderObj = new MultiReader(diskReader, ramReader);

            searcher = new IndexSearcher(diskReader);
            //searcher = new IndexSearcher(indexReaderObj);
            //indexReaderObj.close();
        } catch (Exception e) {
            //do nothing
            e.printStackTrace();
            log.error("init Exception:" + e.getMessage());
        }
    }

    public boolean insertProcessQueue(metaLog metalog) {

        if (metalog != null) {
            return IndexInputQueue.add(metalog);
        }
        return false;
    }

    public void addIndex(metaLog metalog) {
        try {
            Document metainfo = metalog.getDoc();
            //ramWriter.addDocument(metainfo);
            diskWriter.addDocument(metainfo);

        } catch (Exception e) {
            log.error(e.getMessage());
            e.printStackTrace();
        }
    }

    @Scheduled(fixedRate = 5000)
    private void refreshIndex() {

        while (true) {
            metaLog metainfo = IndexInputQueue.poll();
            if (metainfo != null) {
                addIndex(metainfo);
            } else {
                //empty will continue the index
                break;
            }
        }

        Date start = new Date();
        try {
            //reload index
            diskWriter.commit();

            //clean up the ram
            //ramWriter.deleteAll();
            DirectoryReader tmp = diskReader.openIfChanged(diskReader);
            if (tmp != null) {
                diskReader.close();
                diskReader = tmp;
                searcher = new IndexSearcher(diskReader);
            }

        } catch (Exception e) {
            e.printStackTrace();
            log.error(e.getMessage());
        }

        Date end = new Date();
        log.info("Reload Index:" + (end.getTime() - start.getTime()) + " total milliseconds totalcount:" + diskReader.numDocs());

    }

    public responseJson searchIndex(String field, String keyword, int start, int limit) {
        QueryParser parser = new QueryParser(field, analyzer);
        Query query;

        ArrayList<metaLog> metalist = new ArrayList<metaLog>();
        responseJson result = new responseJson();

        try {
            query = parser.parse(keyword);

            TopDocs results = searcher.search(query, limit);

            ScoreDoc[] hits = results.scoreDocs;

            int numTotalHits = results.totalHits;

            //set result count
            result.setTotalcount(numTotalHits);

            limit = Math.min(numTotalHits, limit);

            for (int i = start; i < limit; i++) {

                Document doc = searcher.doc(hits[i].doc);
                metaLog metainfo = new metaLog(doc);
                metalist.add(metainfo);
                /*
                String url = doc.get("url");
                if (url != null) {
                    System.out.println((i + 1) + ". " + url);

                    String title = doc.get("traceid");
                    if (title != null) {
                        System.out.println("traceid: " + title);
                    }
                } else {
                    System.out.println((i + 1) + ". " + "No url for this document");
                }*/

            }
        } catch (Exception e) {
            log.error(e.getMessage());
            e.printStackTrace();
        }

        result.setResult(metalist);
        return result;
    }
}
